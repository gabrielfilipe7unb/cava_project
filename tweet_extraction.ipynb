{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(file_path):\n",
    "    \n",
    "    tweets = []\n",
    "    users_id = []\n",
    "    users_screen_name = []\n",
    "    users_location = []\n",
    "    users_followers_count = []\n",
    "    users_friends_count = []\n",
    "    users_verified = []\n",
    "    tweets_id = []\n",
    "    retweets_count = []\n",
    "    favorites_count = []\n",
    "    langs = []\n",
    "    tweets_full_text = []\n",
    "\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "        for tweet in json_list:\n",
    "            data = json.loads(tweet)\n",
    "            tweets.append(data)\n",
    "            \n",
    "    for tweet in tweets:\n",
    "        users_id.append(tweet['user']['id'])\n",
    "        users_screen_name.append(tweet['user']['screen_name'])\n",
    "        users_location.append(tweet['user']['location'])\n",
    "        users_followers_count.append(tweet['user']['followers_count'])\n",
    "        users_friends_count.append(tweet['user']['friends_count'])\n",
    "        users_verified.append(tweet['user']['verified'])\n",
    "        tweets_id.append(tweet['id'])\n",
    "        retweets_count.append(tweet['retweet_count'])\n",
    "        favorites_count.append(tweet['favorite_count'])\n",
    "        langs.append(tweet['lang'])\n",
    "        tweets_full_text.append(tweet['full_text'])\n",
    "        \n",
    "    df = pd.DataFrame({'users_id': users_id,\n",
    "                       'users_screen_name': users_screen_name,\n",
    "                       'users_location': users_location,\n",
    "                       'users_followers_count': users_followers_count,\n",
    "                       'users_friends_count': users_friends_count,\n",
    "                       'users_verified': users_verified,\n",
    "                       'tweets_id': tweets_id,\n",
    "                       'retweets_count': retweets_count,\n",
    "                       'favorites_count': favorites_count,\n",
    "                       'langs': langs,\n",
    "                       'tweets_full_text': tweets_full_text})\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nubank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nubank_df1 = create_dataframe('data/json/nubank.tweets.jsonl')\n",
    "nubank_df2 = create_dataframe('data/json/nubank_hash.tweets.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nubank_df = pd.concat([nubank_df1, nubank_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nubank_df = nubank_df[(nubank_df['langs'] == 'pt') & (nubank_df['users_screen_name'] != 'nubank')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nubank_df = nubank_df.drop_duplicates(subset=['tweets_full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nubank_df['tweets_full_text'] = nubank_df['tweets_full_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nubank_df = nubank_df.replace([':'],'')\n",
    "nubank_df = nubank_df.replace(['.'],'')\n",
    "nubank_df = nubank_df.replace([','],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nubank_df = nubank_df[~nubank_df['tweets_full_text'].str.contains('doença crônica')]\n",
    "nubank_df = nubank_df[~nubank_df['tweets_full_text'].str.contains('rt')]\n",
    "nubank_df = nubank_df[~nubank_df['tweets_full_text'].str.contains('pix')]\n",
    "nubank_df = nubank_df[~nubank_df['tweets_full_text'].str.contains('picpay')]\n",
    "nubank_df = nubank_df[~nubank_df['tweets_full_text'].str.contains('r$')]\n",
    "nubank_df = nubank_df[~nubank_df['tweets_full_text'].str.contains('venda')]\n",
    "nubank_df = nubank_df[~nubank_df['tweets_full_text'].str.contains('dm')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10506"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nubank_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nubank_df.to_csv('data/csv/nubank_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banco Inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df1 = create_dataframe('data/json/Bancointer.tweets.jsonl')\n",
    "inter_df2 = create_dataframe('data/json/banco_inter.tweets.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df = pd.concat([inter_df1, inter_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df = inter_df[(inter_df['langs'] == 'pt') & (inter_df['users_screen_name'] != 'Bancointer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df = inter_df.drop_duplicates(subset=['tweets_full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df['tweets_full_text'] = inter_df['tweets_full_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df['tweets_full_text'] = inter_df['tweets_full_text'].replace([':'],'')\n",
    "inter_df['tweets_full_text'] = inter_df['tweets_full_text'].replace(['.'],'')\n",
    "inter_df['tweets_full_text'] = inter_df['tweets_full_text'].replace([','],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df = inter_df[~inter_df['tweets_full_text'].str.contains('doença crônica')]\n",
    "inter_df = inter_df[~inter_df['tweets_full_text'].str.contains('rt')]\n",
    "inter_df = inter_df[~inter_df['tweets_full_text'].str.contains('pix')]\n",
    "inter_df = inter_df[~inter_df['tweets_full_text'].str.contains('picpay')]\n",
    "inter_df = inter_df[~inter_df['tweets_full_text'].str.contains('r$')]\n",
    "inter_df = inter_df[~inter_df['tweets_full_text'].str.contains('venda')]\n",
    "inter_df = inter_df[~inter_df['tweets_full_text'].str.contains('dm')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df.to_csv('data/csv/inter_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banco C6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6_df1 = create_dataframe('data/json/c6.tweets.jsonl')\n",
    "c6_df2 = create_dataframe('data/json/C6Bank.tweets.jsonl')\n",
    "c6_df3 = create_dataframe('data/json/banco_c6.tweets.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6_df = pd.concat([c6_df1, c6_df2, c6_df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6_df = c6_df[(c6_df['langs'] == 'pt') & (c6_df['users_screen_name'] != 'C6Bank')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6_df = c6_df.drop_duplicates(subset=['tweets_full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6_df['tweets_full_text'] = c6_df['tweets_full_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6_df['tweets_full_text'] = c6_df['tweets_full_text'].replace([':'],'')\n",
    "c6_df['tweets_full_text'] = c6_df['tweets_full_text'].replace(['.'],'')\n",
    "c6_df['tweets_full_text'] = c6_df['tweets_full_text'].replace([','],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6_df = c6_df[~c6_df['tweets_full_text'].str.contains('doença crônica')]\n",
    "c6_df = c6_df[~c6_df['tweets_full_text'].str.contains('rt')]\n",
    "c6_df = c6_df[~c6_df['tweets_full_text'].str.contains('pix')]\n",
    "c6_df = c6_df[~c6_df['tweets_full_text'].str.contains('picpay')]\n",
    "c6_df = c6_df[~c6_df['tweets_full_text'].str.contains('r$')]\n",
    "c6_df = c6_df[~c6_df['tweets_full_text'].str.contains('venda')]\n",
    "c6_df = c6_df[~c6_df['tweets_full_text'].str.contains('dm')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c6_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6_df.to_csv('data/csv/c6_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banco Next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df1 = create_dataframe('data/json/banco_next.tweets.jsonl')\n",
    "next_df2 = create_dataframe('data/json/falanext.tweets.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df = pd.concat([next_df1, next_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df = next_df[(next_df['langs'] == 'pt') & (next_df['users_screen_name'] != 'falanext')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df = next_df.drop_duplicates(subset=['tweets_full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df['tweets_full_text'] = next_df['tweets_full_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df['tweets_full_text'] = next_df['tweets_full_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df['tweets_full_text'] = next_df['tweets_full_text'].replace([':'],'')\n",
    "next_df['tweets_full_text'] = next_df['tweets_full_text'].replace(['.'],'')\n",
    "next_df['tweets_full_text'] = next_df['tweets_full_text'].replace([','],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df = next_df[~next_df['tweets_full_text'].str.contains('doença crônica')]\n",
    "next_df = next_df[~next_df['tweets_full_text'].str.contains('rt')]\n",
    "next_df = next_df[~next_df['tweets_full_text'].str.contains('pix')]\n",
    "next_df = next_df[~next_df['tweets_full_text'].str.contains('picpay')]\n",
    "next_df = next_df[~next_df['tweets_full_text'].str.contains('r$')]\n",
    "next_df = next_df[~next_df['tweets_full_text'].str.contains('venda')]\n",
    "next_df = next_df[~next_df['tweets_full_text'].str.contains('dm')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users_id</th>\n",
       "      <th>users_screen_name</th>\n",
       "      <th>users_location</th>\n",
       "      <th>users_followers_count</th>\n",
       "      <th>users_friends_count</th>\n",
       "      <th>users_verified</th>\n",
       "      <th>tweets_id</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>favorites_count</th>\n",
       "      <th>langs</th>\n",
       "      <th>tweets_full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>795785230661648384</td>\n",
       "      <td>marieuso</td>\n",
       "      <td>Belém, Brasil</td>\n",
       "      <td>690</td>\n",
       "      <td>539</td>\n",
       "      <td>False</td>\n",
       "      <td>1390718660512190466</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>pt</td>\n",
       "      <td>um lixo o banco next um lixo imprestavel . lix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1389305478837047297</td>\n",
       "      <td>oxinyard</td>\n",
       "      <td></td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>False</td>\n",
       "      <td>1390718389186859009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pt</td>\n",
       "      <td>foi só eu começar a pesquisar sobre abrir cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1378071741684183042</td>\n",
       "      <td>GanheDi85379078</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1390718222329131017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pt</td>\n",
       "      <td>@memenginho 🔥banco next pagando até r$200 por ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1378071741684183042</td>\n",
       "      <td>GanheDi85379078</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1390718017722585095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pt</td>\n",
       "      <td>@boilingcastle 🔥banco next pagando até r$200 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1378071741684183042</td>\n",
       "      <td>GanheDi85379078</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1390717957945368581</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pt</td>\n",
       "      <td>@rick19292830 🔥banco next pagando até r$200 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>112897001</td>\n",
       "      <td>FalleNCS</td>\n",
       "      <td></td>\n",
       "      <td>1103517</td>\n",
       "      <td>1323</td>\n",
       "      <td>True</td>\n",
       "      <td>1387978367702605827</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>pt</td>\n",
       "      <td>@josejorgedlucca @falanext @fallenstorebr mand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>733056324884402181</td>\n",
       "      <td>josejorgedlucca</td>\n",
       "      <td>PR</td>\n",
       "      <td>195</td>\n",
       "      <td>606</td>\n",
       "      <td>False</td>\n",
       "      <td>1387975848192532486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pt</td>\n",
       "      <td>@falanext @fallenstorebr e o cupom não tá func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>733056324884402181</td>\n",
       "      <td>josejorgedlucca</td>\n",
       "      <td>PR</td>\n",
       "      <td>195</td>\n",
       "      <td>606</td>\n",
       "      <td>False</td>\n",
       "      <td>1387975433765990405</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>pt</td>\n",
       "      <td>@falanext @fallencs @fallenstorebr fake! fui h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>1086740901941182465</td>\n",
       "      <td>GiFerro2</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>380</td>\n",
       "      <td>False</td>\n",
       "      <td>1387963603521835011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pt</td>\n",
       "      <td>@fallencs @falanext @fallenstorebr presente pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>132503689</td>\n",
       "      <td>DaniloSoarex</td>\n",
       "      <td>Wakanda - CE</td>\n",
       "      <td>2424</td>\n",
       "      <td>990</td>\n",
       "      <td>False</td>\n",
       "      <td>1387962167975153669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pt</td>\n",
       "      <td>finalmente o next fazendo uma parceria dahora ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 users_id users_screen_name users_location  \\\n",
       "0      795785230661648384          marieuso  Belém, Brasil   \n",
       "1     1389305478837047297          oxinyard                  \n",
       "2     1378071741684183042   GanheDi85379078                  \n",
       "3     1378071741684183042   GanheDi85379078                  \n",
       "4     1378071741684183042   GanheDi85379078                  \n",
       "...                   ...               ...            ...   \n",
       "1550            112897001          FalleNCS                  \n",
       "1551   733056324884402181   josejorgedlucca            PR    \n",
       "1553   733056324884402181   josejorgedlucca            PR    \n",
       "1556  1086740901941182465          GiFerro2                  \n",
       "1557            132503689      DaniloSoarex   Wakanda - CE   \n",
       "\n",
       "      users_followers_count  users_friends_count  users_verified  \\\n",
       "0                       690                  539           False   \n",
       "1                        25                   59           False   \n",
       "2                         1                    1           False   \n",
       "3                         1                    1           False   \n",
       "4                         1                    1           False   \n",
       "...                     ...                  ...             ...   \n",
       "1550                1103517                 1323            True   \n",
       "1551                    195                  606           False   \n",
       "1553                    195                  606           False   \n",
       "1556                     19                  380           False   \n",
       "1557                   2424                  990           False   \n",
       "\n",
       "                tweets_id  retweets_count  favorites_count langs  \\\n",
       "0     1390718660512190466               0                3    pt   \n",
       "1     1390718389186859009               0                0    pt   \n",
       "2     1390718222329131017               0                0    pt   \n",
       "3     1390718017722585095               0                0    pt   \n",
       "4     1390717957945368581               0                0    pt   \n",
       "...                   ...             ...              ...   ...   \n",
       "1550  1387978367702605827               0                9    pt   \n",
       "1551  1387975848192532486               0                0    pt   \n",
       "1553  1387975433765990405               0                2    pt   \n",
       "1556  1387963603521835011               0                0    pt   \n",
       "1557  1387962167975153669               0                0    pt   \n",
       "\n",
       "                                       tweets_full_text  \n",
       "0     um lixo o banco next um lixo imprestavel . lix...  \n",
       "1     foi só eu começar a pesquisar sobre abrir cont...  \n",
       "2     @memenginho 🔥banco next pagando até r$200 por ...  \n",
       "3     @boilingcastle 🔥banco next pagando até r$200 p...  \n",
       "4     @rick19292830 🔥banco next pagando até r$200 po...  \n",
       "...                                                 ...  \n",
       "1550  @josejorgedlucca @falanext @fallenstorebr mand...  \n",
       "1551  @falanext @fallenstorebr e o cupom não tá func...  \n",
       "1553  @falanext @fallencs @fallenstorebr fake! fui h...  \n",
       "1556  @fallencs @falanext @fallenstorebr presente pr...  \n",
       "1557  finalmente o next fazendo uma parceria dahora ...  \n",
       "\n",
       "[513 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df.to_csv('data/csv/next_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
